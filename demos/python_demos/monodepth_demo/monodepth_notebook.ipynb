{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "from argparse import ArgumentParser\n",
    "import cv2\n",
    "import numpy as np\n",
    "import logging as log\n",
    "from openvino.inference_engine import IECore\n",
    "import matplotlib.pyplot as plt\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[ INFO ] creating inference engine\n",
      "[ INFO ] Loading network\n",
      "[ INFO ] preparing input blobs\n",
      "[ INFO ] loading model to the plugin\n",
      "start\n",
      "[ INFO ] starting inference\n",
      "[ INFO ] processing output blob\n",
      "end\n",
      "0.04198932647705078\n",
      "[ INFO ] Color-coded disparity image was saved to 256x256_ryan.png_mono.png\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# logging\n",
    "log.basicConfig(format=\"[ %(levelname)s ] %(message)s\",\n",
    "                level=log.INFO, stream=sys.stdout)\n",
    "\n",
    "log.info(\"creating inference engine\")\n",
    "ie = IECore()\n",
    "\n",
    "log.info(\"Loading network\")\n",
    "# net = ie.read_network(args.model, os.path.splitext(args.model)[0] + \".bin\")\n",
    "net = ie.read_network('model-small.onnx')\n",
    "\n",
    "assert len(net.input_info) == 1, \"Sample supports only single input topologies\"\n",
    "assert len(net.outputs) == 1, \"Sample supports only single output topologies\"\n",
    "\n",
    "log.info(\"preparing input blobs\")\n",
    "input_blob = next(iter(net.input_info))\n",
    "out_blob = next(iter(net.outputs))\n",
    "net.batch_size = 1\n",
    "\n",
    "# read and pre-process input image\n",
    "_, _, height, width = net.input_info[input_blob].input_data.shape\n",
    "\n",
    "input_image = '256x256_ryan.png'\n",
    "\n",
    "image = cv2.imread(input_image, cv2.IMREAD_COLOR)\n",
    "(input_height, input_width) = image.shape[:-1]\n",
    "\n",
    "# resize\n",
    "if (input_height, input_width) != (height, width):\n",
    "    log.info(\"Image is resized from {} to {}\".format(\n",
    "        image.shape[:-1], (height, width)))\n",
    "    image = cv2.resize(image, (width, height), cv2.INTER_CUBIC)\n",
    "\n",
    "# prepare input\n",
    "image = image.astype(np.float32)\n",
    "image = image.transpose((2, 0, 1))\n",
    "image_input = np.expand_dims(image, 0)\n",
    "\n",
    "# loading model to the plugin\n",
    "log.info(\"loading model to the plugin\")\n",
    "exec_net = ie.load_network(network=net, device_name='CPU')\n",
    "\n",
    "start = time.time()\n",
    "print(\"start\")\n",
    "\n",
    "# start sync inference\n",
    "log.info(\"starting inference\")\n",
    "res = exec_net.infer(inputs={input_blob: image_input})\n",
    "\n",
    "# processing output blob\n",
    "log.info(\"processing output blob\")\n",
    "disp = np.squeeze(res[out_blob][0])\n",
    "\n",
    "end = time.time()\n",
    "print(\"end\")\n",
    "print(end - start)\n",
    "\n",
    "# resize disp to input resolution\n",
    "disp = cv2.resize(disp, (input_width, input_height), cv2.INTER_CUBIC)\n",
    "\n",
    "# rescale disp\n",
    "disp_min = disp.min()\n",
    "disp_max = disp.max()\n",
    "\n",
    "if disp_max - disp_min > 1e-6:\n",
    "    disp = (disp - disp_min) / (disp_max - disp_min)\n",
    "else:\n",
    "    disp.fill(0.5)\n",
    "\n",
    "# pfm\n",
    "#     out = 'disp.pfm'\n",
    "#     cv2.imwrite(out, disp)\n",
    "\n",
    "#     log.info(\"Disparity map was saved to {}\".format(out))\n",
    "\n",
    "# png\n",
    "out = f'{input_image}_mono.png'\n",
    "plt.imsave(out, disp, vmin=0, vmax=1, cmap='inferno')\n",
    "\n",
    "log.info(\"Color-coded disparity image was saved to {}\".format(out))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 %\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-memyuvq3\\opencv\\modules\\highgui\\src\\window.cpp:651: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31merror\u001b[0m                                     Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-13-a2ac289514e6>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[1;31m# Just to see the video in real time\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'frame'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mframe\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0mcv2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mimshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m'croped'\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mcrop_frame\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31merror\u001b[0m: OpenCV(4.5.1) C:\\Users\\appveyor\\AppData\\Local\\Temp\\1\\pip-req-build-memyuvq3\\opencv\\modules\\highgui\\src\\window.cpp:651: error: (-2:Unspecified error) The function is not implemented. Rebuild the library with Windows, GTK+ 2.x or Cocoa support. If you are on Ubuntu or Debian, install libgtk2.0-dev and pkg-config, then re-run cmake or configure script in function 'cvShowImage'\n"
     ]
    }
   ],
   "source": [
    "# Open the video\n",
    "cap = cv2.VideoCapture('mono_in_hollis.mp4')\n",
    "\n",
    "# Initialize frame counter\n",
    "cnt = 0\n",
    "\n",
    "# Some characteristics from the original video\n",
    "w_frame, h_frame = int(cap.get(cv2.CAP_PROP_FRAME_WIDTH)), int(cap.get(cv2.CAP_PROP_FRAME_HEIGHT))\n",
    "fps, frames = cap.get(cv2.CAP_PROP_FPS), cap.get(cv2.CAP_PROP_FRAME_COUNT)\n",
    "\n",
    "# Here you can define your croping values\n",
    "x,y,h,w = 0,0,256,256\n",
    "\n",
    "# output\n",
    "fourcc = cv2.VideoWriter_fourcc(*'XVID')\n",
    "out = cv2.VideoWriter('result.avi', fourcc, fps, (w, h))\n",
    "\n",
    "\n",
    "# Now we start\n",
    "while(cap.isOpened()):\n",
    "    ret, frame = cap.read()\n",
    "\n",
    "    cnt += 1 # Counting frames\n",
    "\n",
    "    # Avoid problems when video finish\n",
    "    if ret==True:\n",
    "        # Croping the frame\n",
    "        crop_frame = frame[y:y+h, x:x+w]\n",
    "\n",
    "        # Percentage\n",
    "        xx = cnt *100/frames\n",
    "        print(int(xx),'%')\n",
    "\n",
    "        # Saving from the desired frames\n",
    "        #if 15 <= cnt <= 90:\n",
    "        #    out.write(crop_frame)\n",
    "\n",
    "        # I see the answer now. Here you save all the video\n",
    "        out.write(crop_frame)\n",
    "\n",
    "        # Just to see the video in real time          \n",
    "        cv2.imshow('frame',frame)\n",
    "        cv2.imshow('croped',crop_frame)\n",
    "\n",
    "        if cv2.waitKey(1) & 0xFF == ord('q'):\n",
    "            break\n",
    "    else:\n",
    "        break\n",
    "\n",
    "\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ffmpeg -i mono_in_hollis.mp4 -vf \"crop=256:256:100:100\" -c:a copy out.mp4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
